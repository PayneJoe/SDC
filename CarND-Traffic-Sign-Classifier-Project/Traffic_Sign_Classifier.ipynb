{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:17.373169Z",
     "start_time": "2018-03-31T06:35:17.308156Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "import sys,os,time\n",
    "import tensorflow as tf\n",
    "from contextlib import contextmanager\n",
    "from math import ceil, floor\n",
    "import cv2\n",
    "%matplotlib inline\n",
    "\n",
    "@contextmanager\n",
    "def timer(name):\n",
    "    \"\"\"\n",
    "    Taken from Konstantin Lopuhin https://www.kaggle.com/lopuhin\n",
    "    in script named : Mercari Golf: 0.3875 CV in 75 LOC, 1900 s\n",
    "    https://www.kaggle.com/lopuhin/mercari-golf-0-3875-cv-in-75-loc-1900-s\n",
    "    \"\"\"\n",
    "    t0 = time.time()\n",
    "    yield\n",
    "    print(f'[{name}] done in {time.time() - t0:.0f} s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:17.525326Z",
     "start_time": "2018-03-31T06:35:17.374679Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Load pickled data\n",
    "training_file = 'train.p'\n",
    "validation_file= 'valid.p'\n",
    "testing_file = 'test.p'\n",
    "\n",
    "with open(training_file, mode='rb') as f:\n",
    "    train = pickle.load(f)\n",
    "with open(validation_file, mode='rb') as f:\n",
    "    valid = pickle.load(f)\n",
    "with open(testing_file, mode='rb') as f:\n",
    "    test = pickle.load(f)\n",
    "    \n",
    "X_train, y_train = train['features'], train['labels']\n",
    "X_valid, y_valid = valid['features'], valid['labels']\n",
    "X_test, y_test = test['features'], test['labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:17.651239Z",
     "start_time": "2018-03-31T06:35:17.526874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Propotion of classes in training examples: \n",
      "[ 0.00517256  0.05689819  0.05776028  0.03620794  0.05086353  0.04741516\n",
      "  0.01034512  0.03707003  0.03620794  0.03793212  0.05172562  0.03362166\n",
      "  0.05431191  0.055174    0.01982816  0.01551769  0.01034512  0.02844909\n",
      "  0.03103537  0.00517256  0.00862094  0.00775884  0.00948303  0.01293141\n",
      "  0.00689675  0.03879422  0.01551769  0.00603466  0.0137935   0.00689675\n",
      "  0.01120722  0.01982816  0.00603466  0.01721314  0.01034512  0.03103537\n",
      "  0.00948303  0.00517256  0.05344981  0.00775884  0.00862094  0.00603466\n",
      "  0.00603466]\n",
      "Number of training examples = 34799\n",
      "Number of validation examples = 4410\n",
      "Number of testing examples = 12630\n",
      "Image data shape = (32, 32, 3)\n",
      "Number of classes = 43\n"
     ]
    }
   ],
   "source": [
    "## basic info of data sets\n",
    "# Number of training examples\n",
    "n_train = X_train.shape[0]\n",
    "\n",
    "# Number of validation examples\n",
    "n_validation = X_valid.shape[0]\n",
    "\n",
    "# Number of testing examples.\n",
    "n_test = X_test.shape[0]\n",
    "\n",
    "# What's the shape of an traffic sign image?\n",
    "image_shape = X_train[0].shape\n",
    "\n",
    "# How many unique classes/labels there are in the dataset.\n",
    "n_classes = len(np.unique(y_train))\n",
    "\n",
    "# What propotions do these classes/labels take?\n",
    "p_classes = dict((c, 0) for c in range(n_classes))\n",
    "for l in y_train:\n",
    "    p_classes[l] += 1\n",
    "print('Propotion of classes in training examples: ')\n",
    "print(np.divide(list(p_classes.values()),np.sum(list(p_classes.values()))))\n",
    "\n",
    "print(\"Number of training examples =\", n_train)\n",
    "print(\"Number of validation examples =\", n_validation)\n",
    "print(\"Number of testing examples =\", n_test)\n",
    "print(\"Image data shape =\", image_shape)\n",
    "print(\"Number of classes =\", n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:20.350727Z",
     "start_time": "2018-03-31T06:35:17.652867Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original shape: \n",
      "(34799, 32, 32, 3)\n",
      "(34799,)\n",
      "0 done.\n",
      "1000 done.\n",
      "2000 done.\n",
      "3000 done.\n",
      "4000 done.\n",
      "5000 done.\n",
      "6000 done.\n",
      "7000 done.\n",
      "8000 done.\n",
      "9000 done.\n",
      "10000 done.\n",
      "11000 done.\n",
      "12000 done.\n",
      "13000 done.\n",
      "14000 done.\n",
      "15000 done.\n",
      "16000 done.\n",
      "17000 done.\n",
      "18000 done.\n",
      "19000 done.\n",
      "20000 done.\n",
      "21000 done.\n",
      "22000 done.\n",
      "23000 done.\n",
      "24000 done.\n",
      "25000 done.\n",
      "26000 done.\n",
      "27000 done.\n",
      "28000 done.\n",
      "29000 done.\n",
      "30000 done.\n",
      "31000 done.\n",
      "32000 done.\n",
      "33000 done.\n",
      "34000 done.\n",
      "[Augmentation ] done in 4165 s\n",
      "augmented shape: \n",
      "(417588, 32, 32, 3)\n",
      "(417588,)\n"
     ]
    }
   ],
   "source": [
    "IMAGE_SIZE = 32\n",
    "\n",
    "## visualization for image\n",
    "def plot(image):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(image, cmap=\"gray\")\n",
    "    plt.show()\n",
    "    \n",
    "## random brightness for image\n",
    "def random_brightness(img):\n",
    "    \n",
    "    image = tf.identity(img)\n",
    "    \n",
    "    image = tf.image.random_hue(image, max_delta=0.05)\n",
    "    image = tf.image.random_contrast(image, lower=0.3, upper=1.0)\n",
    "    image = tf.image.random_brightness(image, max_delta=0.1)\n",
    "    image = tf.image.random_saturation(image, lower=0.0, upper=2.0)   \n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    return image\n",
    "# random noise for image\n",
    "def random_noise(img):\n",
    "    \n",
    "    image = tf.identity(img)\n",
    "    \n",
    "    white_mask = tf.fill([32, 32, 3], np.uint8(255))\n",
    "    threshold_mask = tf.fill([32, 32, 3], np.float32(0.1))\n",
    "    noise_img = tf.random_normal(shape= [32, 32, 3], mean= .0, stddev= 0.1, dtype= tf.float32)\n",
    "    noise_mask = tf.multiply(tf.cast(tf.greater(noise_img, threshold_mask), tf.uint8), white_mask)\n",
    "    \n",
    "    image = tf.cast(tf.maximum(tf.cast(image, tf.int32), tf.cast(noise_mask, tf.int32)), tf.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "# fixed deep-brightness for image\n",
    "def fixed_brightness(X_imgs):\n",
    "    \n",
    "    n_samples = len(X_imgs)\n",
    "    brightened_imgs = []\n",
    "    row, col, _ = X_imgs[0].shape\n",
    "    # Gaussian distribution parameters\n",
    "    mean = 0\n",
    "    var = 0.1\n",
    "    sigma = var ** 0.5\n",
    "    \n",
    "    bright_weight = [0.15, 0.25]\n",
    "    \n",
    "    for w in bright_weight:\n",
    "        for i in range(n_samples):\n",
    "            img = X_imgs[i].copy()\n",
    "            gaussian = np.random.random((row, col, 1)).astype(np.float32)\n",
    "            gaussian = np.concatenate((gaussian, gaussian, gaussian), axis = 2)\n",
    "            img = img.astype(np.float32)/255\n",
    "            gaussian_img = cv2.addWeighted(img, w, 0.25 * gaussian, 0.25, 0)\n",
    "            gaussian_img = (gaussian_img * 255).astype(np.uint8).tolist()\n",
    "            brightened_imgs.append(gaussian_img)\n",
    "            \n",
    "    return brightened_imgs\n",
    "# paint white on black part\n",
    "def paintwhite1(img):\n",
    "\n",
    "    image = tf.identity(img)\n",
    "    \n",
    "    m1 = tf.cast(tf.less(image, tf.fill([32, 32, 3], np.uint8(65))), tf.uint8)\n",
    "    white_img = tf.fill([32, 32, 3], np.uint8(255))\n",
    "    \n",
    "    image = tf.maximum(tf.cast(image, tf.int32), tf.cast(tf.multiply(white_img, m1), tf.int32))\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    return image\n",
    "# paint white on red part\n",
    "def paintwhite2(img):\n",
    "    \n",
    "    image = tf.identity(img)\n",
    "    \n",
    "    m1 = tf.cast(tf.less(image, tf.fill([32, 32, 3], np.uint8(120))), tf.uint8)\n",
    "    m2 = tf.cast(tf.greater(image, tf.fill([32, 32, 3], np.uint8(65))), tf.uint8)\n",
    "    m = tf.multiply(m1, m2)\n",
    "    white_img = tf.fill([32, 32, 3], np.uint8(255))\n",
    "    \n",
    "    image = tf.maximum(tf.cast(image, tf.int32), tf.cast(tf.multiply(white_img, m), tf.int32))\n",
    "    image = tf.cast(image, tf.uint8)\n",
    "    \n",
    "    return image\n",
    "\n",
    "## random scale for image\n",
    "def random_scale(img):\n",
    "    \n",
    "    image = tf.identity(img)\n",
    "    \n",
    "    image = tf.divide(tf.cast(image, tf.float32), 255)\n",
    "    image = tf.random_crop(image, size=[24, 24, 3])\n",
    "    image = tf.image.resize_images(image, (32, 32))\n",
    "    image = tf.cast(tf.multiply(image, 255.0), tf.uint8)\n",
    "    \n",
    "    return image\n",
    "# get translate params\n",
    "def get_translate_parameters(index):\n",
    "    if index == 0: # Translate left 20 percent\n",
    "        offset = np.array([0.0, 0.2], dtype = np.float32)\n",
    "        size = np.array([IMAGE_SIZE, ceil(0.8 * IMAGE_SIZE)], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = int(ceil(0.8 * IMAGE_SIZE))\n",
    "        h_start = 0\n",
    "        h_end = IMAGE_SIZE\n",
    "    elif index == 1: # Translate right 20 percent\n",
    "        offset = np.array([0.0, -0.2], dtype = np.float32)\n",
    "        size = np.array([IMAGE_SIZE, ceil(0.8 * IMAGE_SIZE)], dtype = np.int32)\n",
    "        w_start = int(floor((1 - 0.8) * IMAGE_SIZE))\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = 0\n",
    "        h_end = IMAGE_SIZE\n",
    "    elif index == 2: # Translate top 20 percent\n",
    "        offset = np.array([0.2, 0.0], dtype = np.float32)\n",
    "        size = np.array([ceil(0.8 * IMAGE_SIZE), IMAGE_SIZE], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = 0\n",
    "        h_end = int(ceil(0.8 * IMAGE_SIZE)) \n",
    "    else: # Translate bottom 20 percent\n",
    "        offset = np.array([-0.2, 0.0], dtype = np.float32)\n",
    "        size = np.array([ceil(0.8 * IMAGE_SIZE), IMAGE_SIZE], dtype = np.int32)\n",
    "        w_start = 0\n",
    "        w_end = IMAGE_SIZE\n",
    "        h_start = int(floor((1 - 0.8) * IMAGE_SIZE))\n",
    "        h_end = IMAGE_SIZE \n",
    "        \n",
    "    return offset, size, w_start, w_end, h_start, h_end\n",
    "\n",
    "## augmentation for train images\n",
    "def augment_data(dataset, dataset_labels, augementation_factor= 4):\n",
    "    augmented_image = []\n",
    "    augmented_image_labels = []\n",
    "\n",
    "    img_input = tf.placeholder(tf.uint8, (32, 32, 3))\n",
    "    # random brightness\n",
    "    bright = random_brightness(img_input)\n",
    "    # scale\n",
    "    scale = random_scale(img_input)\n",
    "    # random noise\n",
    "    noise = random_noise(img_input)\n",
    "    # paint white\n",
    "    paint = paintwhite1(img_input)\n",
    "    \n",
    "    n = 0\n",
    "    with tf.Session() as sess:\n",
    "        for num in range (0, dataset.shape[0]):\n",
    "            # original image\n",
    "            augmented_image.append(dataset[num].tolist())\n",
    "            augmented_image_labels.append(dataset_labels[num])\n",
    "            for i in range(0, augementation_factor):\n",
    "                # random brightness for image\n",
    "                result_img = sess.run(bright, feed_dict= {img_input: dataset[num]})\n",
    "                augmented_image.append(result_img.tolist())\n",
    "                augmented_image_labels.append(dataset_labels[num])\n",
    "                # random scale for image\n",
    "                result_img = sess.run(scale, feed_dict= {img_input: dataset[num]})\n",
    "                augmented_image.append(result_img.tolist())\n",
    "                augmented_image_labels.append(dataset_labels[num])\n",
    "#                 # paint\n",
    "#                 result_img = sess.run(paint, feed_dict= {img_input: dataset[num]})\n",
    "#                 augmented_image.append(result_img.tolist())\n",
    "#                 augmented_image_labels.append(dataset_labels[num])\n",
    "            # random noise for image\n",
    "            result_img = sess.run(noise, feed_dict= {img_input: dataset[num]})\n",
    "            augmented_image.append(result_img.tolist())\n",
    "            augmented_image_labels.append(dataset_labels[num])\n",
    "                \n",
    "            if((n % 1000) == 0):\n",
    "                print('%s done.' % n)\n",
    "            n += 1\n",
    "#         # translation for images\n",
    "#         offsets = np.zeros((dataset.shape[0], 2), dtype = np.float32)\n",
    "#         n_translations = 4\n",
    "#         for i in range(n_translations):\n",
    "#             X_translated = np.zeros((dataset.shape[0], 32, 32, 3), dtype = np.float32)\n",
    "#             X_translated.fill(1.0) # Filling background color\n",
    "#             base_offset, size, w_start, w_end, h_start, h_end = get_translate_parameters(i)\n",
    "#             offsets[:, :] = base_offset \n",
    "#             glimpses = tf.image.extract_glimpse(dataset/255.0, size, offsets)   \n",
    "#             glimpses = sess.run(glimpses)\n",
    "#             X_translated[:, h_start: h_start + size[0], w_start: w_start + size[1], :] = glimpses\n",
    "#             augmented_image.extend((np.array(X_translated) * 255.0).astype(np.uint8).tolist())\n",
    "#             augmented_image_labels.extend(dataset_labels)\n",
    "        # add fixed deep-brightness for images as deep-darkness exists in certain kinds of images\n",
    "        augmented_image.extend(fixed_brightness(dataset))\n",
    "        augmented_image_labels.extend(dataset_labels)\n",
    "        augmented_image_labels.extend(dataset_labels)\n",
    "    return np.array(augmented_image).astype(np.uint8), np.array(augmented_image_labels)\n",
    "\n",
    "print('original shape: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "with timer('Augmentation '):\n",
    "    X_train, y_train = augment_data(X_train, y_train) # it's a time-consuming preprocess\n",
    "print('augmented shape: ')\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "## debugging for certain kind of images\n",
    "# label = 0\n",
    "# idx = np.argwhere(y_train == label).flatten()\n",
    "# print('size label %s is %s' % (label, len(idx)))\n",
    "# print(X_train.shape)\n",
    "# X_train_1 = X_train[idx,]\n",
    "# y_train_1 = y_train[idx,]\n",
    "# print(X_train_1.shape)\n",
    "# tmp_x = X_train_1[:1,]\n",
    "# tmp_y = y_train_1[:1,]\n",
    "# print(tmp_x.shape)\n",
    "# tmp_x, tmp_y = augment_data(tmp_x, tmp_y)\n",
    "# tmp_x = tmp_x.astype(np.uint8)\n",
    "# for i in range(len(tmp_x)):\n",
    "#     plot(tmp_x[i])\n",
    "# sys.exit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:20.352440Z",
     "start_time": "2018-03-31T06:35:17.312Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## LE-Net architechure\n",
    "# add dropout for these two convolutional layer to avoid overfitting after adding few times of augmentation images\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.layers import flatten\n",
    "\n",
    "def LeNet(x, keep_prob_1, keep_prob_2):    \n",
    "    # Arguments used for tf.truncated_normal, randomly defines variables for the weights and biases for each layer\n",
    "    mu = 0\n",
    "    sigma = 0.1\n",
    "    \n",
    "    filter_1= 6\n",
    "    filter_2= 16\n",
    "    full_1 = 120\n",
    "    full_2 = 84\n",
    "    full_3 = 43\n",
    "    \n",
    "    # Layer 1: Convolutional. Input = 32x32x3. \n",
    "    # out_height = (32 - 5 + 1)/1 = 28,\n",
    "    # out_width = (32 - 5 + 1)/1 = 28,\n",
    "    # out_depth = 6(tunned)\n",
    "    # Output = 28 * 28 * 6\n",
    "    conv1_W = tf.Variable(tf.truncated_normal(shape=(5, 5, 3, filter_1), mean = mu, stddev = sigma))\n",
    "    conv1_b = tf.Variable(tf.zeros(filter_1))\n",
    "    conv1   = tf.nn.conv2d(x, conv1_W, strides=[1, 1, 1, 1], padding='VALID') + conv1_b\n",
    "\n",
    "    conv1_size = int((32 - 5 + 1)/1)\n",
    "    \n",
    "    # Activation.\n",
    "    conv1 = tf.nn.relu(conv1)\n",
    "    conv1 = tf.nn.dropout(conv1, keep_prob_1)\n",
    "\n",
    "    # Pooling. Input = 28x28x6. \n",
    "    # out_height = (28 - 2 + 2)/2 = 14,\n",
    "    # out_width = (28 - 2 + 2)/2 = 14,\n",
    "    # out_depth = 6(handed by conv1)\n",
    "    # Output = 14x14x6.\n",
    "    conv1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    conv1_size = int((conv1_size - 2 + 2)/2)\n",
    "    \n",
    "    # Layer 2: Convolutional. \n",
    "    # out_height = (14 - 5 + 1)/1 = 10,\n",
    "    # out_width = (14 - 5 + 1)/1 = 10,\n",
    "    # out_depth = 16(tunned)\n",
    "    # Output = 10x10x16.\n",
    "    conv2_W = tf.Variable(tf.truncated_normal(shape=(5, 5, filter_1, filter_2), mean = mu, stddev = sigma))\n",
    "    conv2_b = tf.Variable(tf.zeros(filter_2))\n",
    "    conv2   = tf.nn.conv2d(conv1, conv2_W, strides=[1, 1, 1, 1], padding='VALID') + conv2_b\n",
    "    conv2_size = int((conv1_size - 5 + 1)/1)\n",
    "    \n",
    "    # Activation.\n",
    "    conv2 = tf.nn.relu(conv2)\n",
    "    conv2 = tf.nn.dropout(conv2, keep_prob_2)\n",
    "\n",
    "    # Pooling. Input = 10x10x16. \n",
    "    # out_height = (10 - 2 + 2)/2 = 5,\n",
    "    # out_width = (10 - 2 + 2)/2 = 5,\n",
    "    # out_depth = 16(handed by conv2)\n",
    "    # Output = 5x5x16.\n",
    "    conv2 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='VALID')\n",
    "    conv2_size = int((conv2_size - 2 + 2)/2)\n",
    "    \n",
    "    # Flatten. Input = 5x5x16.\n",
    "    # Output = 5 * 5 * 16 = 400.\n",
    "    fc0   = flatten(conv2)\n",
    "    \n",
    "    # Layer 3: Fully Connected. Input = 400. Output = 120.\n",
    "    fc1_W = tf.Variable(tf.truncated_normal(shape=(conv2_size * conv2_size * filter_2, full_1), mean = mu, stddev = sigma))\n",
    "    fc1_b = tf.Variable(tf.zeros(full_1))\n",
    "    fc1   = tf.matmul(fc0, fc1_W) + fc1_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc1    = tf.nn.relu(fc1)\n",
    "\n",
    "    # Layer 4: Fully Connected. Input = 120. Output = 84.\n",
    "    fc2_W  = tf.Variable(tf.truncated_normal(shape=(full_1, full_2), mean = mu, stddev = sigma))\n",
    "    fc2_b  = tf.Variable(tf.zeros(full_2))\n",
    "    fc2    = tf.matmul(fc1, fc2_W) + fc2_b\n",
    "    \n",
    "    # Activation.\n",
    "    fc2    = tf.nn.relu(fc2)\n",
    "\n",
    "    # Layer 5: Fully Connected. Input = 84. Output = 43.\n",
    "    fc3_W  = tf.Variable(tf.truncated_normal(shape=(full_2, full_3), mean = mu, stddev = sigma))\n",
    "    fc3_b  = tf.Variable(tf.zeros(full_3))\n",
    "    logits = tf.matmul(fc2, fc3_W) + fc3_b\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:20.353340Z",
     "start_time": "2018-03-31T06:35:17.313Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n",
      "\n",
      "EPOCH 1 ...\n",
      "Validation Accuracy = 0.615\n",
      "\n",
      "EPOCH 2 ...\n",
      "Validation Accuracy = 0.743\n",
      "\n",
      "EPOCH 3 ...\n",
      "Validation Accuracy = 0.809\n",
      "\n",
      "EPOCH 4 ...\n",
      "Validation Accuracy = 0.843\n",
      "\n",
      "EPOCH 5 ...\n",
      "Validation Accuracy = 0.842\n",
      "\n",
      "EPOCH 6 ...\n",
      "Validation Accuracy = 0.857\n",
      "\n",
      "EPOCH 7 ...\n",
      "Validation Accuracy = 0.871\n",
      "\n",
      "EPOCH 8 ...\n",
      "Validation Accuracy = 0.896\n",
      "\n",
      "EPOCH 9 ...\n",
      "Validation Accuracy = 0.904\n",
      "\n",
      "EPOCH 10 ...\n",
      "Validation Accuracy = 0.893\n",
      "\n",
      "EPOCH 11 ...\n",
      "Validation Accuracy = 0.897\n",
      "\n",
      "EPOCH 12 ...\n",
      "Validation Accuracy = 0.909\n",
      "\n",
      "EPOCH 13 ...\n",
      "Validation Accuracy = 0.923\n",
      "\n",
      "EPOCH 14 ...\n",
      "Validation Accuracy = 0.925\n",
      "\n",
      "EPOCH 15 ...\n",
      "Validation Accuracy = 0.931\n",
      "\n",
      "EPOCH 16 ...\n",
      "Validation Accuracy = 0.932\n",
      "\n",
      "EPOCH 17 ...\n",
      "Validation Accuracy = 0.939\n",
      "\n",
      "EPOCH 18 ...\n",
      "Validation Accuracy = 0.938\n",
      "\n",
      "EPOCH 19 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "EPOCH 20 ...\n",
      "Validation Accuracy = 0.935\n",
      "\n",
      "Model saved\n"
     ]
    }
   ],
   "source": [
    "## super-parameters\n",
    "rate = 0.001\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "## TF logic for optimization \n",
    "x = tf.placeholder(tf.float32, (None, 32, 32, 3))\n",
    "y = tf.placeholder(tf.int32, (None))\n",
    "one_hot_y = tf.one_hot(y, 43)\n",
    "keep_prob_1 = tf.placeholder(tf.float32)\n",
    "keep_prob_2 = tf.placeholder(tf.float32)\n",
    "\n",
    "logits = LeNet(x, keep_prob_1, keep_prob_2)\n",
    "cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=one_hot_y, logits=logits)\n",
    "loss_operation = tf.reduce_mean(cross_entropy)\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate = rate)\n",
    "training_operation = optimizer.minimize(loss_operation)\n",
    "\n",
    "## TF logic for evaluation\n",
    "correct_prediction = tf.equal(tf.argmax(logits, 1), tf.argmax(one_hot_y, 1))\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "## have the dropout rate being 1.0 while inferring\n",
    "def evaluate(X_data, y_data):\n",
    "    num_examples = len(X_data)\n",
    "    total_accuracy = 0\n",
    "    sess = tf.get_default_session()\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x, batch_y = X_data[offset:offset+BATCH_SIZE], y_data[offset:offset+BATCH_SIZE]\n",
    "        accuracy = sess.run(accuracy_operation, feed_dict={x: batch_x, y: batch_y, keep_prob_1: 1.0, keep_prob_2: 1.0})\n",
    "        total_accuracy += (accuracy * len(batch_x))\n",
    "    return total_accuracy / num_examples\n",
    "\n",
    "## training/evaluation\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    num_examples = len(X_train)\n",
    "    \n",
    "    print(\"Training...\")\n",
    "    print()\n",
    "    for i in range(EPOCHS):\n",
    "        X_train, y_train = shuffle(X_train, y_train)\n",
    "        for offset in range(0, num_examples, BATCH_SIZE):\n",
    "            end = offset + BATCH_SIZE\n",
    "            batch_x, batch_y = X_train[offset:end], y_train[offset:end]\n",
    "            sess.run(training_operation, feed_dict={x: batch_x, y: batch_y, keep_prob_1: 0.5, keep_prob_2: 0.8})\n",
    "            \n",
    "        validation_accuracy = evaluate(X_valid, y_valid)\n",
    "        print(\"EPOCH {} ...\".format(i+1))\n",
    "        print(\"Validation Accuracy = {:.3f}\".format(validation_accuracy))\n",
    "        print()\n",
    "        \n",
    "    saver.save(sess, './lenet')\n",
    "    print(\"Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:20.354307Z",
     "start_time": "2018-03-31T06:35:17.314Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "Test Accuracy = 0.922\n"
     ]
    }
   ],
   "source": [
    "## prediction on test\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "\n",
    "    test_accuracy = evaluate(X_test, y_test)\n",
    "    print(\"Test Accuracy = {:.3f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:20.355058Z",
     "start_time": "2018-03-31T06:35:17.315Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12630\n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "softmax probabilities for top-5\n",
      "[[  1.00000000e+00   1.15803521e-11   4.73817737e-15   3.43409413e-15\n",
      "    2.28801874e-15]\n",
      " [  9.99097347e-01   9.02673230e-04   6.65766819e-09   5.11011544e-09\n",
      "    1.12162102e-09]\n",
      " [  1.00000000e+00   9.63164336e-13   4.20131730e-15   2.00624677e-16\n",
      "    5.38932106e-19]\n",
      " [  9.99999881e-01   1.37170630e-07   9.16270781e-10   3.48453406e-12\n",
      "    1.24606271e-13]\n",
      " [  1.00000000e+00   7.27998994e-09   2.48490645e-10   1.65691877e-10\n",
      "    1.96118313e-11]\n",
      " [  1.00000000e+00   1.64203456e-10   1.81412556e-12   2.10540502e-13\n",
      "    2.84813584e-16]\n",
      " [  1.00000000e+00   5.73345038e-10   2.59111885e-14   4.45502749e-16\n",
      "    4.70488119e-20]\n",
      " [  1.00000000e+00   2.81536661e-09   1.62122826e-09   3.73088421e-10\n",
      "    1.79921675e-10]\n",
      " [  1.00000000e+00   6.08894716e-14   2.80523421e-14   3.05764579e-15\n",
      "    1.05020407e-15]\n",
      " [  9.99936581e-01   5.81592540e-05   3.79253515e-06   1.49792038e-06\n",
      "    3.50149421e-09]]\n",
      "\n",
      "Distribution for top-5: \n",
      "[0.0201, 0.064, 0.0605, 0.0412, 0.0434, 0.0738, 0.0075, 0.0512, 0.0335, 0.0269, 0.0305, 0.0343, 0.0279, 0.0175, 0.0239, 0.021, 0.0156, 0.014, 0.0123, 0.0092, 0.0162, 0.0153, 0.0073, 0.0177, 0.0179, 0.0171, 0.0127, 0.0151, 0.0133, 0.0134, 0.018, 0.0184, 0.0125, 0.0137, 0.0215, 0.0278, 0.03, 0.0132, 0.0237, 0.0077, 0.0217, 0.0084, 0.0091]\n",
      "\n",
      "Distribution for truth: \n",
      "[0.0048000002, 0.057, 0.0594, 0.035599999, 0.052299999, 0.049899999, 0.0119, 0.035599999, 0.035599999, 0.037999999, 0.052299999, 0.033300001, 0.0546, 0.057, 0.021400001, 0.0166, 0.0119, 0.0285, 0.0309, 0.0048000002, 0.0071, 0.0071, 0.0094999997, 0.0119, 0.0071, 0.037999999, 0.0143, 0.0048000002, 0.0119, 0.0071, 0.0119, 0.021400001, 0.0048000002, 0.0166, 0.0094999997, 0.0309, 0.0094999997, 0.0048000002, 0.0546, 0.0071, 0.0071, 0.0048000002, 0.0071]\n"
     ]
    }
   ],
   "source": [
    "## analysis with top-k softmax probabilities\n",
    "import sys,os\n",
    "\n",
    "softmax = tf.nn.softmax(logits)\n",
    "\n",
    "k = 5\n",
    "num_examples = len(X_test)\n",
    "print(num_examples)\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x = X_test[offset:offset+BATCH_SIZE]\n",
    "        if(offset == 0):\n",
    "            pred_y = sess.run(softmax, feed_dict={x: batch_x, keep_prob_1: 1.0, keep_prob_2: 1.0})\n",
    "        else:\n",
    "            pred_y = np.vstack([pred_y, sess.run(softmax, feed_dict={x: batch_x, keep_prob_1: 1.0, keep_prob_2: 1.0})])\n",
    "    topk = sess.run(tf.nn.top_k(tf.constant(pred_y), k= k))\n",
    "    \n",
    "    ## top-k softmax value\n",
    "    print('softmax probabilities for top-%s' % k)\n",
    "    print(topk.values[:10])\n",
    "    \n",
    "    flattened_topk = topk.indices.reshape(1, -1).tolist()[0]\n",
    "    pred_dist = dict((i, 0.0) for i in range(43))\n",
    "    for v in flattened_topk:\n",
    "        pred_dist[v] += (1.0/(k * num_examples))\n",
    "    encoded_y = sess.run(one_hot_y, feed_dict= {y: y_test})\n",
    "    y_dist = (1.0 * np.sum(encoded_y, axis= 0))/num_examples\n",
    "    print('\\nDistribution for top-%s: ' % k)\n",
    "    print([round(pred_dist[k], 4) for k in pred_dist])\n",
    "    \n",
    "    print('\\nDistribution for truth: ')\n",
    "    print([round(v, 4) for v in y_dist])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-03-31T06:35:20.356249Z",
     "start_time": "2018-03-31T06:35:17.316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total size for test 12630 \n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "\n",
      "Recall for labels with the top-10 lowest recall: \n",
      "[ 0.76666665  0.82666665  0.85000002  0.88412696  0.89333332  0.89696968\n",
      "  0.94666666  0.95200002  0.97083336  0.98124999]\n",
      "\n",
      "Labels with the top-10 lowest recall: \n",
      "[30 27 24 21 41 23  7 18  6 26]\n",
      "INFO:tensorflow:Restoring parameters from ./lenet\n",
      "\n",
      "Debugging for label 30: \n",
      "\n",
      "Index of truth postive: \n",
      "[   41    72   114   127   237   287   443   496   501   587   620   723\n",
      "   749   883  1025  1096  1214  1402  1422  1514  1524  1582  1697  1709\n",
      "  1713  1824  1976  2072  2109  2288  2360  2361  2599  2600  2655  2660\n",
      "  2682  2760  2864  2993  3025  3043  3049  3273  3387  3567  3745  3778\n",
      "  3782  3799  4011  4069  4070  4133  4367  4383  4509  4511  4525  4579\n",
      "  4639  4833  4953  4985  5280  5313  5363  5779  5802  5806  5824  5851\n",
      "  6004  6090  6139  6146  6310  6458  6487  6529  6603  6658  6836  7072\n",
      "  7081  7090  7115  7246  7255  7400  7439  7448  7461  7525  7559  7693\n",
      "  7700  7811  7884  7907  7977  8063  8126  8348  8510  8549  8624  8705\n",
      "  8722  8818  8824  8826  8974  9140  9170  9246  9335  9411  9661  9692\n",
      "  9769 10016 10223 10264 10297 10489 10584 10659 10825 10968 11012 11074\n",
      " 11173 11410 11435 11439 11451 11495 11564 11617 11634 11709 11746 11830\n",
      " 11904 11925 12252 12346 12476 12563]\n",
      "\n",
      "Index of predicted positive: \n",
      "[   41   427   501   587  1025  1086  1096  1422  1514  1582  1709  1824\n",
      "  1976  2003  2072  2288  2360  2481  2655  2660  2760  2993  3043  3172\n",
      "  3256  3387  3485  3626  3745  3782  4069  4070  4415  4525  4532  4639\n",
      "  4743  5313  5597  5806  5824  5838  5851  6139  6146  6458  6487  6836\n",
      "  6838  7081  7115  7439  7448  7559  7633  7700  7811  8052  8063  8126\n",
      "  8348  8549  8671  8705  8722  8824  8826  8974  9017  9111  9140  9242\n",
      "  9335  9506  9661 10124 10223 10297 10489 10659 10825 10968 11144 11312\n",
      " 11439 11529 11634 11709 11746 11830 11874 12377 12476 12569]\n",
      "\n",
      "Size of misclassified label 30 is 84: \n",
      "\n",
      "Index of misclassified positive: \n",
      "[72, 114, 127, 237, 287, 443, 496, 620, 723, 749, 883, 1214, 1402, 1524, 1697, 1713, 2109, 2361, 2599, 2600, 2682, 2864, 3025, 3049, 3273, 3567, 3778, 3799, 4011, 4133, 4367, 4383, 4509, 4511, 4579, 4833, 4953, 4985, 5280, 5363, 5779, 5802, 6004, 6090, 6310, 6529, 6603, 6658, 7072, 7090, 7246, 7255, 7400, 7461, 7525, 7693, 7884, 7907, 7977, 8510, 8624, 8818, 9170, 9246, 9411, 9692, 9769, 10016, 10264, 10584, 11012, 11074, 11173, 11410, 11435, 11451, 11495, 11564, 11617, 11904, 11925, 12252, 12346, 12563]\n",
      "\n",
      "Misclassified label for label 30: \n",
      "[11 11 20 38 11 23 11 11 11 29 23 11 28 28 28 23 11 11 11 11 11 11 28 11 11\n",
      " 19 20 11 28 11 11 11 29 28 11 28 11 29 23 11 23 11 11 20 26 28 11 11 11 23\n",
      " 11 11 11 28 20 28 23 29 11 11 38 20 11 11 11 11 11 23 11 11 11 28 20 11  4\n",
      " 11 11 12 29 11 28 11 11 11]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nToiR2AkxEjshRmInxP8A99Y+vTer7e4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c4b3837b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label 11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNswekDbMHpA2zB6Q/h8nclLbHGTSqwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c4b3a4d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label 28\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\naWT2gDQye0D6H62phn9Iz2K8AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c4b36d5f8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label 11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c4b3326a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label 11\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAFsAAABZCAYAAABR/liSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLoiJ2AUxEbsgJmIXxETsgvg/3Hi9XejA7pwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c4b48f320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted label 11\n"
     ]
    }
   ],
   "source": [
    "def plot(img):\n",
    "    plt.figure(figsize=(1,1))\n",
    "    plt.imshow(img, cmap=\"gray\")\n",
    "    plt.show()\n",
    "\n",
    "## analysis with top-k lowest recall for individual labels\n",
    "one_hot_pred = tf.one_hot(tf.argmax(softmax, 1), 43)\n",
    "# y_pred_equal = tf.equal(one_hot_y, one_hot_pred)\n",
    "y_pred_mult = tf.multiply(one_hot_y, one_hot_pred)\n",
    "tp = tf.reduce_sum(y_pred_mult, 0)\n",
    "t_n = tf.reduce_sum(one_hot_y, 0)\n",
    "\n",
    "# collect top-k labels with lowest recall\n",
    "k = 10\n",
    "num_examples = len(X_test)\n",
    "print('Total size for test %s ' % num_examples)\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    sess.run(tf.local_variables_initializer())\n",
    "\n",
    "    for offset in range(0, num_examples, BATCH_SIZE):\n",
    "        batch_x = X_test[offset: offset + BATCH_SIZE]\n",
    "        batch_y = y_test[offset: offset + BATCH_SIZE]\n",
    "        if(offset == 0):\n",
    "            tp_mat = sess.run(tp, feed_dict={x: batch_x, y: batch_y, keep_prob_1: 1.0, keep_prob_2: 1.0})\n",
    "            t_n_mat = sess.run(t_n, feed_dict={y: batch_y})\n",
    "        else:\n",
    "            tp_mat = np.vstack([tp_mat, sess.run(tp, feed_dict={x: batch_x, y: batch_y, keep_prob_1: 1.0, keep_prob_2: 1.0})])\n",
    "            t_n_mat = np.vstack([t_n_mat, sess.run(t_n, feed_dict={y: batch_y})])\n",
    "    individual_recall = np.sum(tp_mat, 0) / np.sum(t_n_mat, 0)\n",
    "    print('\\nRecall for labels with the top-%s lowest recall: ' % k)\n",
    "    topk_recall = np.sort(individual_recall[:k])\n",
    "    print(topk_recall)\n",
    "    print('\\nLabels with the top-%s lowest recall: ' % k)\n",
    "    topk_label = np.argsort(individual_recall)[:k]\n",
    "    print(topk_label)   \n",
    "# visualize some of these misclassified image\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('.'))\n",
    "    \n",
    "    pred_mat = sess.run(one_hot_pred, feed_dict= {x: X_test, keep_prob_1: 1.0, keep_prob_2: 1.0})\n",
    "    y_mat = sess.run(one_hot_y, feed_dict={y: y_test}) \n",
    "    y_pred_mult_mat = np.multiply(pred_mat, y_mat)\n",
    "    # for label 27\n",
    "    debug_label = 30\n",
    "    print('\\nDebugging for label %s: ' % debug_label)\n",
    "    pos_idx = np.argwhere(np.transpose(y_mat[:, debug_label]) == 1).flatten()\n",
    "    pred_pos_idx = np.argwhere(np.transpose(pred_mat[:, debug_label]) == 1).flatten()\n",
    "    print('\\nIndex of truth postive: ')\n",
    "    print(pos_idx)\n",
    "    print('\\nIndex of predicted positive: ')\n",
    "    print(pred_pos_idx)\n",
    "    mis_pos_idx = [v for v in pos_idx if(v not in pred_pos_idx)]\n",
    "    print('\\nSize of misclassified label %s is %s: ' % (debug_label, len(mis_pos_idx)))\n",
    "    print('\\nIndex of misclassified positive: ')\n",
    "    print(mis_pos_idx)\n",
    "    mis_pred_label = np.argmax(pred_mat[mis_pos_idx,:], 1)\n",
    "    print('\\nMisclassified label for label %s: ' % debug_label)\n",
    "    print(mis_pred_label)\n",
    "    # sample the last 10 misclassified image, visualize them, see what characters they reside\n",
    "    s = 5\n",
    "    for i in range(s):\n",
    "        img = X_test[mis_pos_idx[-(s - i)]].squeeze()\n",
    "        plot(img)\n",
    "        print('predicted label %s' % mis_pred_label[- (s - i)])\n",
    "        \n",
    "## notable charactertics of misclassified labels\n",
    "# 1. darkness\n",
    "# 2. noising pixels\n",
    "# 3. scale size\n",
    "## improvement strategies\n",
    "# 1. brighten for images\n",
    "# 2. add perputation noise\n",
    "# 3. zoom in/out for images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
